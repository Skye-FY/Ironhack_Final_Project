{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37464bitbaseconda0c233075484a40799281f2bc71354035",
   "display_name": "Python 3.7.4 64-bit ('base': conda)"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt  \n",
    "import seaborn as sns  \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "c19 = pd.read_csv('../data/time_series_19-covid-Confirmed.csv')\n",
    "c19a = c19[c19.columns[4:]]\n",
    "case_sum = [list(c19a[i]) for i in c19a.columns]\n",
    "c19b = c19.T[4:]\n",
    "c19b['Confirmed'] = list(map(lambda x:sum(x), case_sum))\n",
    "c19b = c19b.drop(columns=c19b.columns[:-1]).reset_index().rename(columns={'index':'Date'}).reset_index().rename(columns={'index':'Ticks'})\n",
    "c19b['Date'] = pd.to_datetime(c19b['Date'])\n",
    "X = c19b[['Date']]\n",
    "y = np.array(c19b.Confirmed)\n",
    "train_data = X[:10]\n",
    "test_data = X[10:]\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First we’ll scale our train and test data with MinMaxScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(train_data)\n",
    "scaled_train_data = scaler.transform(train_data)\n",
    "scaled_test_data = scaler.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "`start_index+length=12 > end_index=9` is disallowed, as no part of the sequence would be left to be used as current step.",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-b6533af4bd3e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mn_input\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m12\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mn_features\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mgenerator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTimeseriesGenerator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscaled_train_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscaled_train_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlength\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_input\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras_preprocessing\\sequence.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, targets, length, sampling_rate, stride, start_index, end_index, shuffle, reverse, batch_size)\u001b[0m\n\u001b[0;32m    353\u001b[0m                              \u001b[1;34m'is disallowed, as no part of the sequence '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    354\u001b[0m                              \u001b[1;34m'would be left to be used as current step.'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 355\u001b[1;33m                              % (self.start_index, self.end_index))\n\u001b[0m\u001b[0;32m    356\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    357\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: `start_index+length=12 > end_index=9` is disallowed, as no part of the sequence would be left to be used as current step."
     ]
    }
   ],
   "source": [
    "#Before creating LSTM model we should create a Time Series Generator object.\n",
    "from keras.preprocessing.sequence import TimeseriesGenerator\n",
    "\n",
    "n_input = 12\n",
    "n_features= 1\n",
    "generator = TimeseriesGenerator(scaled_train_data, scaled_train_data, length=n_input)\n",
    "\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "\n",
    "lstm_model = Sequential()\n",
    "lstm_model.add(LSTM(200, activation='relu', input_shape=(n_input, n_features)))\n",
    "lstm_model.add(Dense(1))\n",
    "lstm_model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "lstm_model.summary()\n",
    "\n",
    "lstm_model.fit_generator(generator,epochs=20)\n",
    "\n",
    "losses_lstm = lstm_model.history.history['loss']\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xticks(np.arange(0,21,1))\n",
    "plt.plot(range(len(losses_lstm)),losses_lstm);\n",
    "\n",
    "lstm_predictions_scaled = list()\n",
    "\n",
    "batch = scaled_train_data[-n_input:]\n",
    "current_batch = batch.reshape((1, n_input, n_features))\n",
    "\n",
    "for i in range(len(test_data)):   \n",
    "    lstm_pred = lstm_model.predict(current_batch)[0]\n",
    "    lstm_predictions_scaled.append(lstm_pred) \n",
    "    current_batch = np.append(current_batch[:,1:,:],[[lstm_pred]],axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'lstm_predictions_scaled' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-5bff72aaf3f2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#As you know we scaled our data that’s why we have to inverse it to see true predictions.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mlstm_predictions_scaled\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mlstm_predictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlstm_predictions_scaled\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mlstm_predictions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'lstm_predictions_scaled' is not defined"
     ]
    }
   ],
   "source": [
    "#As you know we scaled our data that’s why we have to inverse it to see true predictions.\n",
    "lstm_predictions_scaled\n",
    "\n",
    "lstm_predictions = scaler.inverse_transform(lstm_predictions_scaled)\n",
    "lstm_predictions\n",
    "\n",
    "test_data['LSTM_Predictions'] = lstm_predictions\n",
    "test_data\n",
    "\n",
    "test_data['Monthly beer production'].plot(figsize = (16,5), legend=True)\n",
    "test_data['LSTM_Predictions'].plot(legend = True);\n",
    "\n",
    "lstm_rmse_error = rmse(test_data['Monthly beer production'], test_data[\"LSTM_Predictions\"])\n",
    "lstm_mse_error = lstm_rmse_error**2\n",
    "mean_value = df['Monthly beer production'].mean()\n",
    "\n",
    "print(f'MSE Error: {lstm_mse_error}\\nRMSE Error: {lstm_rmse_error}\\nMean: {mean_value}')\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}